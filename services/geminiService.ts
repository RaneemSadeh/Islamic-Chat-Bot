
import { GoogleGenAI, Type } from "@google/genai";
import type { GeminiResponse } from '../types';

// AI Development Note: In a real-world RAG system, this service would be a full backend.
// It would first take the user's query and convert it into a vector embedding.
// Then, it would search a vector database (e.g., Pinecone, ChromaDB) for the most similar text chunks.
// Finally, it would construct a prompt with that retrieved context and the user's query to send to the LLM.
// Here, we simulate this entire process by asking Gemini to generate a plausible response based on a detailed prompt.

const getSystemInstruction = () => `
You are an advanced AI assistant acting as an Islamic chatbot based on a Retrieval Augmented Generation (RAG) system. Your knowledge base includes IslamWeb, handwritten manuscripts, and other Islamic texts. When a user asks a question in Arabic, you must follow these steps:
1. Internally, simulate retrieving the most relevant text chunk from your knowledge base.
2. Generate a response in the exact JSON format specified in the schema. Do not add any text outside of the JSON object. Your entire output must be a single, valid JSON object.
`;

export const getIslamicBotResponse = async (query: string): Promise<GeminiResponse> => {
  if (!process.env.API_KEY) {
    throw new Error("API_KEY environment variable not set.");
  }
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
  
  try {
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash",
      contents: `User Question: "${query}"`,
      config: {
        systemInstruction: getSystemInstruction(),
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            rephrasedAnswer: {
              type: Type.STRING,
              description: "An eloquent, rephrased explanation of the answer in Arabic, suitable for the user's question.",
            },
            originalText: {
              type: Type.STRING,
              description: "The original Arabic text retrieved from the source that forms the basis of the answer.",
            },
            source: {
              type: Type.OBJECT,
              properties: {
                name: {
                  type: Type.STRING,
                  description: "The name of the source book or website (e.g., 'صحيح البخاري' or 'IslamWeb').",
                },
                reference: {
                  type: Type.STRING,
                  description: "The specific reference, like a page number, hadith number, or URL (e.g., 'صفحة 23' or 'fatwa/12345').",
                },
              },
              required: ["name", "reference"],
            },
            aiNote: {
              type: Type.STRING,
              description: "A brief, technical note in English explaining the simulated backend process. Example: 'AI Note: This response simulates the RAG process. The\\'originalText\\' and \\'source\\' are plausible excerpts generated by the LLM to mimic retrieval from a vector database.'",
            },
          },
          required: ["rephrasedAnswer", "originalText", "source", "aiNote"],
        },
      },
    });

    const jsonText = response.text.trim();
    const parsedResponse = JSON.parse(jsonText) as GeminiResponse;
    return parsedResponse;
  } catch (error) {
    console.error("Error calling Gemini API:", error);
    throw new Error("Failed to get response from the AI. Please check the console for details.");
  }
};
